name: 'databricks'
version: '1.0.0'
config-version: 2

profile: "databricks"

model-paths: ["models"]
analysis-paths: ["analyses"]
test-paths: ["tests"]
macro-paths: ["macros"]
snapshot-paths: ["snapshots"]

target-path: "target"  # directory which will store compiled SQL files
clean-targets:         # directories to be removed by `dbt clean`
  - "target"
  - "dbt_packages"

dispatch:
  - macro_namespace: dbt_utils
    search_order: ['spark_utils', 'dbt_utils']

models:
  databricks:
    # Automatically add/remove cols & load new data
    # note this does not backfill data; for that you need to do `dbt run --full-refresh`
    on_schema_change: sync_all_columns